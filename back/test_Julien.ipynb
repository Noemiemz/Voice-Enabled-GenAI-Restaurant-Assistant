{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacf3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vibevoice.processor.vibevoice_streaming_processor import VibeVoiceStreamingProcessor\n",
    "from vibevoice.modular.modeling_vibevoice_streaming_inference import VibeVoiceStreamingForConditionalGenerationInference\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519867aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A5\\!S9\\LLM and GenAI\\Project\\.project_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\julie\\.cache\\huggingface\\hub\\models--microsoft--VibeVoice-Realtime-0.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "d:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A5\\!S9\\LLM and GenAI\\Project\\.project_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\julie\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-0.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'. \n",
      "The class this function is called from is 'VibeVoiceTextTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "processor = VibeVoiceStreamingProcessor.from_pretrained(\"microsoft/VibeVoice-Realtime-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c06d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vibevoice.processor.vibevoice_streaming_processor.VibeVoiceStreamingProcessor at 0x1bf91225150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(\n",
    "    \"microsoft/VibeVoice-Realtime-0.5B\",\n",
    "    torch_dtype = torch.float32,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    device_map=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174f5f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mHello, my name is Roger and I am your personal restaurant assistant. How can I help you today?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m inputs = \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_input_with_cached_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A5\\!S9\\LLM and GenAI\\Project\\Voice-Enabled-GenAI-Restaurant-Assistant\\back\\src\\vibevoice\\processor\\vibevoice_streaming_processor.py:220\u001b[39m, in \u001b[36mVibeVoiceStreamingProcessor.process_input_with_cached_prompt\u001b[39m\u001b[34m(self, text, cached_prompt, padding, truncation, max_length, return_tensors, return_attention_mask, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_input, cached_prompt_input \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(texts, cached_prompts):\n\u001b[32m    219\u001b[39m     script_tokens = \u001b[38;5;28mself\u001b[39m.tokenizer.encode(text_input.strip() + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     input_id_length = \u001b[43mcached_prompt_input\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mlast_hidden_state\u001b[39m\u001b[33m'\u001b[39m].size(\u001b[32m1\u001b[39m)\n\u001b[32m    221\u001b[39m     tts_lm_input_id_length = cached_prompt_input[\u001b[33m'\u001b[39m\u001b[33mtts_lm\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlast_hidden_state\u001b[39m\u001b[33m'\u001b[39m].size(\u001b[32m1\u001b[39m)\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# psudo input ids and masks\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "text = \"Hello, my name is Roger and I am your personal restaurant assistant. How can I help you today?\"\n",
    "\n",
    "inputs = processor.process_input_with_cached_prompt(\n",
    "    text=text,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
